{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740513370146,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "_UQWX_YgmShY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from models.AlexNet import AlexNet\n",
    "from models.VGG13 import VGG13\n",
    "# from models.FrankNet import FrankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1740513371607,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "CKCVotU2mh4m",
    "outputId": "8f02dcab-e990-42d3-f0fa-b5a6d5fc4ae4"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((227,227)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=64)\n",
    "test_loader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1740513371894,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "LwD_4CpKnvFy",
    "outputId": "9e824288-75ae-4e3f-ef4d-d24372724063"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740513371902,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "cJoll5r5pe5v"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740513371925,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "70u5DpdQpmdC"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # Obtém o tamanho do dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    # Indica que o modelo está em processo de treinamento\n",
    "    model.train()\n",
    "\n",
    "    # Define a loss total do treinamento\n",
    "    totalLoss = 0\n",
    "\n",
    "    # Itera sobre os lotes\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # transforma as entradas no formato do dispositivo utilizado (CPU ou GPU)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Faz a predição para os valores atuais dos parâmetros\n",
    "        pred = model(X)\n",
    "\n",
    "        # Estima o valor da função de perda\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Incrementa a loss total\n",
    "        totalLoss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "\n",
    "        # Limpa os gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Estima os gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os pesos da rede\n",
    "        optimizer.step()\n",
    "\n",
    "        # LOG: A cada 100 lotes (iterações) mostra a perda\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    print(f\"Epoch average loss: {totalLoss/len(dataloader):>7f}\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # Obtém o tamanho do dataset\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Obtém o número de lotes (iterações)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    # Indica que o modelo está em processo de teste\n",
    "    model.eval()\n",
    "\n",
    "    # Inicializa a perda de teste e a quantidade de acertos com 0\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Desabilita o cálculo do gradiente\n",
    "    with torch.no_grad():\n",
    "        # Itera sobre o conjunto de teste\n",
    "        for X, y in dataloader:\n",
    "            # transforma as entradas no formato do dispositivo utilizado (CPU ou GPU)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Realiza a predição\n",
    "            pred = model(X)\n",
    "\n",
    "            # Calcula a perda\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # Verifica se a predição foi correta\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    # Determina a perda média e a proporção de acertos\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    # LOG: mostra a acurácia e a perda\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "executionInfo": {
     "elapsed": 21944,
     "status": "error",
     "timestamp": 1740513393852,
     "user": {
      "displayName": "JOAO VICTOR CORREA DE ALMEIDA",
      "userId": "08522568365246387241"
     },
     "user_tz": 180
    },
    "id": "ffGWDhVcpqik",
    "outputId": "57035562-c3e2-41de-8004-c93e42a23449"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"-------------------------------\\nEpoch {t+1}\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the test data and generate predictions\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9VAiQkBVvBrODyrlVHWtf",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
